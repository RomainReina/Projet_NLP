{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Projet_NLP_REINAROMAIN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RomainReina/Projet_NLP/blob/main/Projet_NLP_REINAROMAIN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n8gjHp8jwH6j",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "93e2fe02-ba76-4cdf-99a3-e9b3564d09b5"
      },
      "source": [
        "# Import Python libraries and helper functions \r\n",
        "from keras.datasets import imdb\r\n",
        "import pandas as pd\r\n",
        "import numpy as np\r\n",
        "from keras.layers import LSTM, Activation, Dropout, Dense, Input\r\n",
        "from keras.layers.embeddings import Embedding\r\n",
        "from keras.models import Model\r\n",
        "import string\r\n",
        "import re\r\n",
        "from keras.preprocessing.text import Tokenizer\r\n",
        "from sklearn.preprocessing import LabelBinarizer\r\n",
        "from keras.preprocessing.sequence import pad_sequences\r\n",
        "import keras\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "\r\n",
        "from nltk.tokenize import word_tokenize\r\n",
        "from nltk.text import Text\r\n",
        "from nltk.stem.lancaster import LancasterStemmer\r\n",
        "from nltk.stem import WordNetLemmatizer\r\n",
        "import nltk\r\n",
        "\r\n",
        "import numpy as np\r\n",
        "import pandas as pd\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "\r\n",
        "nltk.download('punkt')\r\n",
        "nltk.download('stopwords')\r\n",
        "nltk.download('wordnet')\r\n",
        "nltk.download('averaged_perceptron_tagger')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pbYDGro7g9qB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6144b100-4470-485c-8738-e9bd64b2e4c6"
      },
      "source": [
        "from google.colab import drive\r\n",
        "drive.mount('/content/gdrive',force_remount= True)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 441
        },
        "id": "FenOCLzGgEtg",
        "outputId": "8d4e27ee-f3c7-48fc-9a01-2061e35a6a40"
      },
      "source": [
        "csv = pd.read_csv(\"gdrive/MyDrive/Projet_NLP/training.1600000.processed.noemoticon.csv\",encoding = \"ISO-8859-1\")\r\n",
        "csv"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1467810369</th>\n",
              "      <th>Mon Apr 06 22:19:45 PDT 2009</th>\n",
              "      <th>NO_QUERY</th>\n",
              "      <th>_TheSpecialOne_</th>\n",
              "      <th>@switchfoot http://twitpic.com/2y1zl - Awww, that's a bummer.  You shoulda got David Carr of Third Day to do it. ;D</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1467810672</td>\n",
              "      <td>Mon Apr 06 22:19:49 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>scotthamilton</td>\n",
              "      <td>is upset that he can't update his Facebook by ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>1467810917</td>\n",
              "      <td>Mon Apr 06 22:19:53 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>mattycus</td>\n",
              "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>1467811184</td>\n",
              "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>ElleCTF</td>\n",
              "      <td>my whole body feels itchy and like its on fire</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>1467811193</td>\n",
              "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>Karoli</td>\n",
              "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>1467811372</td>\n",
              "      <td>Mon Apr 06 22:20:00 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>joy_wolf</td>\n",
              "      <td>@Kwesidei not the whole crew</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1599994</th>\n",
              "      <td>4</td>\n",
              "      <td>2193601966</td>\n",
              "      <td>Tue Jun 16 08:40:49 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>AmandaMarie1028</td>\n",
              "      <td>Just woke up. Having no school is the best fee...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1599995</th>\n",
              "      <td>4</td>\n",
              "      <td>2193601969</td>\n",
              "      <td>Tue Jun 16 08:40:49 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>TheWDBoards</td>\n",
              "      <td>TheWDB.com - Very cool to hear old Walt interv...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1599996</th>\n",
              "      <td>4</td>\n",
              "      <td>2193601991</td>\n",
              "      <td>Tue Jun 16 08:40:49 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>bpbabe</td>\n",
              "      <td>Are you ready for your MoJo Makeover? Ask me f...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1599997</th>\n",
              "      <td>4</td>\n",
              "      <td>2193602064</td>\n",
              "      <td>Tue Jun 16 08:40:49 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>tinydiamondz</td>\n",
              "      <td>Happy 38th Birthday to my boo of alll time!!! ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1599998</th>\n",
              "      <td>4</td>\n",
              "      <td>2193602129</td>\n",
              "      <td>Tue Jun 16 08:40:50 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>RyanTrevMorris</td>\n",
              "      <td>happy #charitytuesday @theNSPCC @SparksCharity...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1599999 rows × 6 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         0  ...  @switchfoot http://twitpic.com/2y1zl - Awww, that's a bummer.  You shoulda got David Carr of Third Day to do it. ;D\n",
              "0        0  ...  is upset that he can't update his Facebook by ...                                                                  \n",
              "1        0  ...  @Kenichan I dived many times for the ball. Man...                                                                  \n",
              "2        0  ...    my whole body feels itchy and like its on fire                                                                   \n",
              "3        0  ...  @nationwideclass no, it's not behaving at all....                                                                  \n",
              "4        0  ...                      @Kwesidei not the whole crew                                                                   \n",
              "...     ..  ...                                                ...                                                                  \n",
              "1599994  4  ...  Just woke up. Having no school is the best fee...                                                                  \n",
              "1599995  4  ...  TheWDB.com - Very cool to hear old Walt interv...                                                                  \n",
              "1599996  4  ...  Are you ready for your MoJo Makeover? Ask me f...                                                                  \n",
              "1599997  4  ...  Happy 38th Birthday to my boo of alll time!!! ...                                                                  \n",
              "1599998  4  ...  happy #charitytuesday @theNSPCC @SparksCharity...                                                                  \n",
              "\n",
              "[1599999 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cI0GH22xggOF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "f613eeca-d0c1-42e2-f41d-04e34ce1bf6f"
      },
      "source": [
        "data = csv.drop(['1467810369','Mon Apr 06 22:19:45 PDT 2009','NO_QUERY','_TheSpecialOne_'],axis = 1)\r\n",
        "data.columns = ['index', 'comments']\r\n",
        "data\r\n"
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>comments</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>is upset that he can't update his Facebook by ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>my whole body feels itchy and like its on fire</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>@Kwesidei not the whole crew</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1599994</th>\n",
              "      <td>4</td>\n",
              "      <td>Just woke up. Having no school is the best fee...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1599995</th>\n",
              "      <td>4</td>\n",
              "      <td>TheWDB.com - Very cool to hear old Walt interv...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1599996</th>\n",
              "      <td>4</td>\n",
              "      <td>Are you ready for your MoJo Makeover? Ask me f...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1599997</th>\n",
              "      <td>4</td>\n",
              "      <td>Happy 38th Birthday to my boo of alll time!!! ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1599998</th>\n",
              "      <td>4</td>\n",
              "      <td>happy #charitytuesday @theNSPCC @SparksCharity...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1599999 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         index                                           comments\n",
              "0            0  is upset that he can't update his Facebook by ...\n",
              "1            0  @Kenichan I dived many times for the ball. Man...\n",
              "2            0    my whole body feels itchy and like its on fire \n",
              "3            0  @nationwideclass no, it's not behaving at all....\n",
              "4            0                      @Kwesidei not the whole crew \n",
              "...        ...                                                ...\n",
              "1599994      4  Just woke up. Having no school is the best fee...\n",
              "1599995      4  TheWDB.com - Very cool to hear old Walt interv...\n",
              "1599996      4  Are you ready for your MoJo Makeover? Ask me f...\n",
              "1599997      4  Happy 38th Birthday to my boo of alll time!!! ...\n",
              "1599998      4  happy #charitytuesday @theNSPCC @SparksCharity...\n",
              "\n",
              "[1599999 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "-RC9o6zJgh4r",
        "outputId": "d6b4469b-6d32-4f09-8b42-af678c00f027"
      },
      "source": [
        "\r\n",
        "n = 200\r\n",
        "#j'en veux que 200 + et 200 - \r\n",
        "negative_value = data[-n:]\r\n",
        "positive_value = data[:n]\r\n",
        "data_liste = positive_value\r\n",
        "data_liste"
      ],
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>comments</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>is upset that he can't update his Facebook by ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>my whole body feels itchy and like its on fire</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>@Kwesidei not the whole crew</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>195</th>\n",
              "      <td>0</td>\n",
              "      <td>wanttss to go out</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>196</th>\n",
              "      <td>0</td>\n",
              "      <td>Is not going to sleep tonite.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>197</th>\n",
              "      <td>0</td>\n",
              "      <td>too worried and tired to post tonight</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>198</th>\n",
              "      <td>0</td>\n",
              "      <td>couldn't get shit done today ~ i'm so screwed</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>199</th>\n",
              "      <td>0</td>\n",
              "      <td>Job Interview in Cardiff today, wish me luck! ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>200 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     index                                           comments\n",
              "0        0  is upset that he can't update his Facebook by ...\n",
              "1        0  @Kenichan I dived many times for the ball. Man...\n",
              "2        0    my whole body feels itchy and like its on fire \n",
              "3        0  @nationwideclass no, it's not behaving at all....\n",
              "4        0                      @Kwesidei not the whole crew \n",
              "..     ...                                                ...\n",
              "195      0                                 wanttss to go out \n",
              "196      0                     Is not going to sleep tonite. \n",
              "197      0             too worried and tired to post tonight \n",
              "198      0     couldn't get shit done today ~ i'm so screwed \n",
              "199      0  Job Interview in Cardiff today, wish me luck! ...\n",
              "\n",
              "[200 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 105
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VUw7nWESgjC8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9bfd6761-9453-40df-d31c-47d00a6abd03"
      },
      "source": [
        "print(len(data_liste))\r\n",
        "data_train8 = data_liste['comments']   # on crée la liste du voca"
      ],
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "200\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6pu0Qtvatoyd"
      },
      "source": [
        " # Traitemeent de Texte"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RZjKmJ8xss7N",
        "outputId": "01c46b79-dbfe-4fa6-8651-39697f350301"
      },
      "source": [
        "#Minuscule\r\n",
        "for k in range(len(data_train)):\r\n",
        "    data_train[k] = data_train8[k].lower()\r\n",
        "    \r\n",
        "#Tokenization\r\n",
        "tokenizer = nltk.RegexpTokenizer(r'\\w+')\r\n",
        "\r\n",
        "for k in range(len(data_train)):\r\n",
        "    data_train[k] = tokenizer.tokenize(data_train[k])\r\n",
        "    \r\n",
        "#Stopwords\r\n",
        "for k in range(len(data_train)):\r\n",
        "    data_train[k] = [w for w in data_train[k] if not w in list(nltk.corpus.stopwords.words('english'))]\r\n",
        "    \r\n",
        "#Lemmatization\r\n",
        "Word_Lemmatizer = WordNetLemmatizer()\r\n",
        "\r\n",
        "for k in range(len(data_train)):\r\n",
        "    data_train[k] = [Word_Lemmatizer.lemmatize(w) for w in data_train[k]]\r\n",
        "\r\n",
        "print(\"First sentence: \")\r\n",
        "print(data_liste[\"comments\"][0])\r\n",
        "\r\n",
        "print(\"First sentence embeded: \")\r\n",
        "print(data_train[0])\r\n",
        "\r\n",
        "    \r\n"
      ],
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n",
            "/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2882: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  if __name__ == '__main__':\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:13: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  del sys.path[0]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "First sentence: \n",
            "is upset that he can't update his Facebook by texting it... and might cry as a result  School today also. Blah!\n",
            "First sentence embeded: \n",
            "['upset', 'update', 'facebook', 'texting', 'might', 'cry', 'result', 'school', 'today', 'also', 'blah']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:19: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wR6T72d5tucq"
      },
      "source": [
        "# Train"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BnCPzmwv6Y5Q"
      },
      "source": [
        "building vocab\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dU_tzALa6XN6",
        "outputId": "bb725771-2d12-43bf-e02b-f946e587b8fb"
      },
      "source": [
        "from collections import defaultdict\r\n",
        "\r\n",
        "vocab = defaultdict(lambda: 0)\r\n",
        "vocab['<PAD>'] = 1\r\n",
        "\r\n",
        "for idx in range(len(data_train)):\r\n",
        "    q = data_train[idx]\r\n",
        "    for word in q:\r\n",
        "        if word not in vocab:\r\n",
        "            vocab[word] = len(vocab) + 1\r\n",
        "print('The length of the vocabulary is: ', len(vocab))"
      ],
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The length of the vocabulary is:  959\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kJHPi0hj6W0s",
        "outputId": "4062e6af-122f-4da0-db47-e3cf6c683cf0"
      },
      "source": [
        "print(vocab['<PAD>'])\r\n",
        "print(vocab['update'])\r\n",
        "print(vocab['Astronomy'])  #not in vocabulary, returns 0"
      ],
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1\n",
            "3\n",
            "0\n",
            "0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VjXLLPHUtv4d"
      },
      "source": [
        "def data_generator(batch_size, pos_data, neg_data, vocab, shuffle=False, verbose=False):\r\n",
        "    '''\r\n",
        "      Input: \r\n",
        "        batch_size - integer describing the batch size\r\n",
        "        pos_data - list containing sentences where sentence are positive\r\n",
        "        neg_data - list containing sentences where sentence are positive\r\n",
        "        shuffle - Shuffle the data order\r\n",
        "        pad - an integer representing a pad character\r\n",
        "        verbose - Print information during runtime\r\n",
        "      Output:\r\n",
        "        a tuple containing 2 elements:\r\n",
        "        X - np.ndarray of dim (batch_size, max_len) of padded sentences\r\n",
        "        Y - np.ndarray of dim (batch_size, max_len) of tags associated with the sentences in X\r\n",
        "    '''\r\n",
        "    \r\n",
        "    # count the number of lines in data_lines\r\n",
        "    num_lines = len(x)\r\n",
        "    \r\n",
        "    # create an array with the indexes of data_lines that can be shuffled\r\n",
        "    lines_index = [*range(num_lines)]\r\n",
        "    \r\n",
        "    # shuffle the indexes if shuffle is set to True\r\n",
        "    if shuffle:\r\n",
        "        rnd.shuffle(lines_index)\r\n",
        "    \r\n",
        "    index = 0 # tracks current location in x, y\r\n",
        "    while True:\r\n",
        "        buffer_x = [0] * batch_size # Temporal array to store the raw x data for this batch\r\n",
        "        buffer_y = [0] * batch_size # Temporal array to store the raw y data for this batch\r\n",
        "                \r\n",
        "  ### START CODE HERE (Replace instances of 'None' with your code) ###\r\n",
        "        \r\n",
        "        # Copy into the temporal buffers the sentences in x[index : index + batch_size] \r\n",
        "        # along with their corresponding labels y[index : index + batch_size]\r\n",
        "        # Find maximum length of sentences in x[index : index + batch_size] for this batch. \r\n",
        "        # Reset the index if we reach the end of the data set, and shuffle the indexes if needed.\r\n",
        "        max_len = 0\r\n",
        "        for i in range(batch_size):\r\n",
        "             # if the index is greater than or equal to the number of lines in x\r\n",
        "            if index >= num_lines:\r\n",
        "                # then reset the index to 0\r\n",
        "                index = 0\r\n",
        "                # re-shuffle the indexes if shuffle is set to True\r\n",
        "                if shuffle:\r\n",
        "                    rnd.shuffle(lines_index)\r\n",
        "            \r\n",
        "            # The current position is obtained using `lines_index[index]`\r\n",
        "            # Store the x value at the current position into the buffer_x\r\n",
        "            buffer_x[i] = x[lines_index[index]]\r\n",
        "            \r\n",
        "            # Store the y value at the current position into the buffer_y\r\n",
        "            buffer_y[i] = y[lines_index[index]]\r\n",
        "            \r\n",
        "            lenx = len(x[lines_index[index]])    #length of current x[]\r\n",
        "            if lenx > max_len:\r\n",
        "                max_len = lenx                   #max_len tracks longest x[]\r\n",
        "            \r\n",
        "            # increment index by one\r\n",
        "            index += 1\r\n",
        "\r\n",
        "\r\n",
        "        # create X,Y, NumPy arrays of size (batch_size, max_len) 'full' of pad value\r\n",
        "        X = np.full((batch_size, max_len), pad)\r\n",
        "        Y = np.full((batch_size, max_len), pad)\r\n",
        "\r\n",
        "        # copy values from lists to NumPy arrays. Use the buffered values\r\n",
        "        for i in range(batch_size):\r\n",
        "            # get the example (sentence as a tensor)\r\n",
        "            # in `buffer_x` at the `i` index\r\n",
        "            x_i = buffer_x[i]\r\n",
        "            \r\n",
        "            # similarly, get the example's labels\r\n",
        "            # in `buffer_y` at the `i` index\r\n",
        "            y_i = buffer_y[i]\r\n",
        "            \r\n",
        "            # Walk through each word in x_i\r\n",
        "            for j in range(len(x_i)):\r\n",
        "                # store the word in x_i at position j into X\r\n",
        "                X[i, j] = x_i[j]\r\n",
        "                \r\n",
        "                # store the label in y_i at position j into Y\r\n",
        "                Y[i, j] = y_i[j]\r\n",
        "\r\n",
        "    ### END CODE HERE ###\r\n",
        "        if verbose: print(\"index=\", index)\r\n",
        "        yield((X,Y))"
      ],
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EdnJIW-F5k-p"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}